# coding: utf-8

"""
    GSI Floating-Point 32 API

    **Introduction**<br> GSI Technology’s floating-point similarity search API provides an accessible gateway to running searches on GSI’s Gemini® Associative Processing Unit (APU).<br> It works in conjunction with the GSI system management solution which enables users to work with multiple APU boards simultaneously for improved performance.<br><br> **Dataset and Query Format**<br> Dataset embeddings can be in 32- or 64-bit floating point format, and any number of features, e.g. 256 or 512 (there is no upper limit).<br> Query embeddings must have the same floating-point format and number of features as used in the dataset.<br> GSI performs the search and delivers the top-k most similar results.  # noqa: E501

    OpenAPI spec version: 1.0
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

import pprint
import re  # noqa: F401

import six

class ImportDatasetRequest(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """
    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'records': 'OneOfImportDatasetRequestRecords',
        'records_file_type': 'str',
        'dataset_id': 'str',
        'storage_type': 'str',
        'search_type': 'str',
        'train_ind': 'bool',
        'train_type': 'str',
        'nbits': 'int',
        'qbits': 'int',
        'target_accuracy': 'float',
        'metadata_of_records': 'OneOfImportDatasetRequestMetadataOfRecords',
        'md_unique': 'bool',
        'convert_to_dataset': 'bool',
        'num_of_boards': 'int',
        'num_of_clusters': 'int',
        'dataset_name': 'str',
        'dataset_type': 'str',
        'ef_construction': 'int',
        'm_number_of_edges': 'int',
        'distance_function': 'str',
        'hnsw_use_ssd': 'bool'
    }

    attribute_map = {
        'records': 'records',
        'records_file_type': 'recordsFileType',
        'dataset_id': 'datasetId',
        'storage_type': 'storageType',
        'search_type': 'searchType',
        'train_ind': 'trainInd',
        'train_type': 'trainType',
        'nbits': 'nbits',
        'qbits': 'qbits',
        'target_accuracy': 'targetAccuracy',
        'metadata_of_records': 'metadataOfRecords',
        'md_unique': 'mdUnique',
        'convert_to_dataset': 'convertToDataset',
        'num_of_boards': 'numOfBoards',
        'num_of_clusters': 'numOfClusters',
        'dataset_name': 'datasetName',
        'dataset_type': 'datasetType',
        'ef_construction': 'efConstruction',
        'm_number_of_edges': 'mNumberOfEdges',
        'distance_function': 'distanceFunction',
        'hnsw_use_ssd': 'hnswUseSSD'
    }

    def __init__(self, records=None, records_file_type='npy', dataset_id=None, storage_type=None, search_type='flat', train_ind=False, train_type='Regular', nbits=768, qbits=768, target_accuracy=None, metadata_of_records=None, md_unique=False, convert_to_dataset=False, num_of_boards=None, num_of_clusters=None, dataset_name=None, dataset_type=None, ef_construction=100, m_number_of_edges=32, distance_function='cosine', hnsw_use_ssd=False):  # noqa: E501
        """ImportDatasetRequest - a model defined in Swagger"""  # noqa: E501
        self._records = None
        self._records_file_type = None
        self._dataset_id = None
        self._storage_type = None
        self._search_type = None
        self._train_ind = None
        self._train_type = None
        self._nbits = None
        self._qbits = None
        self._target_accuracy = None
        self._metadata_of_records = None
        self._md_unique = None
        self._convert_to_dataset = None
        self._num_of_boards = None
        self._num_of_clusters = None
        self._dataset_name = None
        self._dataset_type = None
        self._ef_construction = None
        self._m_number_of_edges = None
        self._distance_function = None
        self._hnsw_use_ssd = None
        self.discriminator = None
        self.records = records
        if records_file_type is not None:
            self.records_file_type = records_file_type
        if dataset_id is not None:
            self.dataset_id = dataset_id
        if storage_type is not None:
            self.storage_type = storage_type
        if search_type is not None:
            self.search_type = search_type
        if train_ind is not None:
            self.train_ind = train_ind
        if train_type is not None:
            self.train_type = train_type
        if nbits is not None:
            self.nbits = nbits
        if qbits is not None:
            self.qbits = qbits
        if target_accuracy is not None:
            self.target_accuracy = target_accuracy
        if metadata_of_records is not None:
            self.metadata_of_records = metadata_of_records
        if md_unique is not None:
            self.md_unique = md_unique
        if convert_to_dataset is not None:
            self.convert_to_dataset = convert_to_dataset
        if num_of_boards is not None:
            self.num_of_boards = num_of_boards
        if num_of_clusters is not None:
            self.num_of_clusters = num_of_clusters
        if dataset_name is not None:
            self.dataset_name = dataset_name
        if dataset_type is not None:
            self.dataset_type = dataset_type
        if ef_construction is not None:
            self.ef_construction = ef_construction
        if m_number_of_edges is not None:
            self.m_number_of_edges = m_number_of_edges
        if distance_function is not None:
            self.distance_function = distance_function
        if hnsw_use_ssd is not None:
            self.hnsw_use_ssd = hnsw_use_ssd

    @property
    def records(self):
        """Gets the records of this ImportDatasetRequest.  # noqa: E501


        :return: The records of this ImportDatasetRequest.  # noqa: E501
        :rtype: OneOfImportDatasetRequestRecords
        """
        return self._records

    @records.setter
    def records(self, records):
        """Sets the records of this ImportDatasetRequest.


        :param records: The records of this ImportDatasetRequest.  # noqa: E501
        :type: OneOfImportDatasetRequestRecords
        """
        if records is None:
            raise ValueError("Invalid value for `records`, must not be `None`")  # noqa: E501

        self._records = records

    @property
    def records_file_type(self):
        """Gets the records_file_type of this ImportDatasetRequest.  # noqa: E501

        indicates the records file type  # noqa: E501

        :return: The records_file_type of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._records_file_type

    @records_file_type.setter
    def records_file_type(self, records_file_type):
        """Sets the records_file_type of this ImportDatasetRequest.

        indicates the records file type  # noqa: E501

        :param records_file_type: The records_file_type of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """
        allowed_values = ["npy", "h5", "fvecs", "list"]  # noqa: E501
        if records_file_type not in allowed_values:
            raise ValueError(
                "Invalid value for `records_file_type` ({0}), must be one of {1}"  # noqa: E501
                .format(records_file_type, allowed_values)
            )

        self._records_file_type = records_file_type

    @property
    def dataset_id(self):
        """Gets the dataset_id of this ImportDatasetRequest.  # noqa: E501

        The UID represent a dataset get it from /dataset/create  # noqa: E501

        :return: The dataset_id of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._dataset_id

    @dataset_id.setter
    def dataset_id(self, dataset_id):
        """Sets the dataset_id of this ImportDatasetRequest.

        The UID represent a dataset get it from /dataset/create  # noqa: E501

        :param dataset_id: The dataset_id of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """

        self._dataset_id = dataset_id

    @property
    def storage_type(self):
        """Gets the storage_type of this ImportDatasetRequest.  # noqa: E501

        indicates the type of the storage, if S3 we need to download it to local filesystem  # noqa: E501

        :return: The storage_type of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._storage_type

    @storage_type.setter
    def storage_type(self, storage_type):
        """Sets the storage_type of this ImportDatasetRequest.

        indicates the type of the storage, if S3 we need to download it to local filesystem  # noqa: E501

        :param storage_type: The storage_type of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """

        self._storage_type = storage_type

    @property
    def search_type(self):
        """Gets the search_type of this ImportDatasetRequest.  # noqa: E501

        Flag indicates if the dataset search type will be clustered/flat/hnsw.  # noqa: E501

        :return: The search_type of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._search_type

    @search_type.setter
    def search_type(self, search_type):
        """Sets the search_type of this ImportDatasetRequest.

        Flag indicates if the dataset search type will be clustered/flat/hnsw.  # noqa: E501

        :param search_type: The search_type of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """
        allowed_values = ["flat", "clusters", "hnsw"]  # noqa: E501
        if search_type not in allowed_values:
            raise ValueError(
                "Invalid value for `search_type` ({0}), must be one of {1}"  # noqa: E501
                .format(search_type, allowed_values)
            )

        self._search_type = search_type

    @property
    def train_ind(self):
        """Gets the train_ind of this ImportDatasetRequest.  # noqa: E501

        Flag that indicates whether a dataset should be trained. (for float32 default is True, for other default is False)  # noqa: E501

        :return: The train_ind of this ImportDatasetRequest.  # noqa: E501
        :rtype: bool
        """
        return self._train_ind

    @train_ind.setter
    def train_ind(self, train_ind):
        """Sets the train_ind of this ImportDatasetRequest.

        Flag that indicates whether a dataset should be trained. (for float32 default is True, for other default is False)  # noqa: E501

        :param train_ind: The train_ind of this ImportDatasetRequest.  # noqa: E501
        :type: bool
        """

        self._train_ind = train_ind

    @property
    def train_type(self):
        """Gets the train_type of this ImportDatasetRequest.  # noqa: E501

        Flag that indicates whether the train should be optimized. Grid/Optuna train is taking longer time than Regular train.  # noqa: E501

        :return: The train_type of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._train_type

    @train_type.setter
    def train_type(self, train_type):
        """Sets the train_type of this ImportDatasetRequest.

        Flag that indicates whether the train should be optimized. Grid/Optuna train is taking longer time than Regular train.  # noqa: E501

        :param train_type: The train_type of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """
        allowed_values = ["Regular", "Grid", "Optuna"]  # noqa: E501
        if train_type not in allowed_values:
            raise ValueError(
                "Invalid value for `train_type` ({0}), must be one of {1}"  # noqa: E501
                .format(train_type, allowed_values)
            )

        self._train_type = train_type

    @property
    def nbits(self):
        """Gets the nbits of this ImportDatasetRequest.  # noqa: E501

        If dataset is float, nbits is the value to convert the float dataset into  # noqa: E501

        :return: The nbits of this ImportDatasetRequest.  # noqa: E501
        :rtype: int
        """
        return self._nbits

    @nbits.setter
    def nbits(self, nbits):
        """Sets the nbits of this ImportDatasetRequest.

        If dataset is float, nbits is the value to convert the float dataset into  # noqa: E501

        :param nbits: The nbits of this ImportDatasetRequest.  # noqa: E501
        :type: int
        """

        self._nbits = nbits

    @property
    def qbits(self):
        """Gets the qbits of this ImportDatasetRequest.  # noqa: E501

        If dataset is float and search type is clusters, qbits is the value to convert the float centroids into  # noqa: E501

        :return: The qbits of this ImportDatasetRequest.  # noqa: E501
        :rtype: int
        """
        return self._qbits

    @qbits.setter
    def qbits(self, qbits):
        """Sets the qbits of this ImportDatasetRequest.

        If dataset is float and search type is clusters, qbits is the value to convert the float centroids into  # noqa: E501

        :param qbits: The qbits of this ImportDatasetRequest.  # noqa: E501
        :type: int
        """

        self._qbits = qbits

    @property
    def target_accuracy(self):
        """Gets the target_accuracy of this ImportDatasetRequest.  # noqa: E501

        Expected accuracy for optimal Hamming K calculation.  # noqa: E501

        :return: The target_accuracy of this ImportDatasetRequest.  # noqa: E501
        :rtype: float
        """
        return self._target_accuracy

    @target_accuracy.setter
    def target_accuracy(self, target_accuracy):
        """Sets the target_accuracy of this ImportDatasetRequest.

        Expected accuracy for optimal Hamming K calculation.  # noqa: E501

        :param target_accuracy: The target_accuracy of this ImportDatasetRequest.  # noqa: E501
        :type: float
        """

        self._target_accuracy = target_accuracy

    @property
    def metadata_of_records(self):
        """Gets the metadata_of_records of this ImportDatasetRequest.  # noqa: E501


        :return: The metadata_of_records of this ImportDatasetRequest.  # noqa: E501
        :rtype: OneOfImportDatasetRequestMetadataOfRecords
        """
        return self._metadata_of_records

    @metadata_of_records.setter
    def metadata_of_records(self, metadata_of_records):
        """Sets the metadata_of_records of this ImportDatasetRequest.


        :param metadata_of_records: The metadata_of_records of this ImportDatasetRequest.  # noqa: E501
        :type: OneOfImportDatasetRequestMetadataOfRecords
        """

        self._metadata_of_records = metadata_of_records

    @property
    def md_unique(self):
        """Gets the md_unique of this ImportDatasetRequest.  # noqa: E501

        indicating if the values in metadata are unique (vector-ids)  # noqa: E501

        :return: The md_unique of this ImportDatasetRequest.  # noqa: E501
        :rtype: bool
        """
        return self._md_unique

    @md_unique.setter
    def md_unique(self, md_unique):
        """Sets the md_unique of this ImportDatasetRequest.

        indicating if the values in metadata are unique (vector-ids)  # noqa: E501

        :param md_unique: The md_unique of this ImportDatasetRequest.  # noqa: E501
        :type: bool
        """

        self._md_unique = md_unique

    @property
    def convert_to_dataset(self):
        """Gets the convert_to_dataset of this ImportDatasetRequest.  # noqa: E501

        Indicating whether the input file should be converted to a dataset  # noqa: E501

        :return: The convert_to_dataset of this ImportDatasetRequest.  # noqa: E501
        :rtype: bool
        """
        return self._convert_to_dataset

    @convert_to_dataset.setter
    def convert_to_dataset(self, convert_to_dataset):
        """Sets the convert_to_dataset of this ImportDatasetRequest.

        Indicating whether the input file should be converted to a dataset  # noqa: E501

        :param convert_to_dataset: The convert_to_dataset of this ImportDatasetRequest.  # noqa: E501
        :type: bool
        """

        self._convert_to_dataset = convert_to_dataset

    @property
    def num_of_boards(self):
        """Gets the num_of_boards of this ImportDatasetRequest.  # noqa: E501

        Used to for cluster search only. numOfBoards will define the num of clusters to create.  # noqa: E501

        :return: The num_of_boards of this ImportDatasetRequest.  # noqa: E501
        :rtype: int
        """
        return self._num_of_boards

    @num_of_boards.setter
    def num_of_boards(self, num_of_boards):
        """Sets the num_of_boards of this ImportDatasetRequest.

        Used to for cluster search only. numOfBoards will define the num of clusters to create.  # noqa: E501

        :param num_of_boards: The num_of_boards of this ImportDatasetRequest.  # noqa: E501
        :type: int
        """

        self._num_of_boards = num_of_boards

    @property
    def num_of_clusters(self):
        """Gets the num_of_clusters of this ImportDatasetRequest.  # noqa: E501

        If numOfBoards is empty, numOfClusters will be used to define the num of clusters to create.  # noqa: E501

        :return: The num_of_clusters of this ImportDatasetRequest.  # noqa: E501
        :rtype: int
        """
        return self._num_of_clusters

    @num_of_clusters.setter
    def num_of_clusters(self, num_of_clusters):
        """Sets the num_of_clusters of this ImportDatasetRequest.

        If numOfBoards is empty, numOfClusters will be used to define the num of clusters to create.  # noqa: E501

        :param num_of_clusters: The num_of_clusters of this ImportDatasetRequest.  # noqa: E501
        :type: int
        """

        self._num_of_clusters = num_of_clusters

    @property
    def dataset_name(self):
        """Gets the dataset_name of this ImportDatasetRequest.  # noqa: E501

        Optional name to associated with the dataset id  # noqa: E501

        :return: The dataset_name of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._dataset_name

    @dataset_name.setter
    def dataset_name(self, dataset_name):
        """Sets the dataset_name of this ImportDatasetRequest.

        Optional name to associated with the dataset id  # noqa: E501

        :param dataset_name: The dataset_name of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """

        self._dataset_name = dataset_name

    @property
    def dataset_type(self):
        """Gets the dataset_type of this ImportDatasetRequest.  # noqa: E501

        Dataset type given by user  # noqa: E501

        :return: The dataset_type of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._dataset_type

    @dataset_type.setter
    def dataset_type(self, dataset_type):
        """Sets the dataset_type of this ImportDatasetRequest.

        Dataset type given by user  # noqa: E501

        :param dataset_type: The dataset_type of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """
        allowed_values = ["binary", "float32"]  # noqa: E501
        if dataset_type not in allowed_values:
            raise ValueError(
                "Invalid value for `dataset_type` ({0}), must be one of {1}"  # noqa: E501
                .format(dataset_type, allowed_values)
            )

        self._dataset_type = dataset_type

    @property
    def ef_construction(self):
        """Gets the ef_construction of this ImportDatasetRequest.  # noqa: E501

        controls the size of the candidate queue for edges when adding a node to the graph  # noqa: E501

        :return: The ef_construction of this ImportDatasetRequest.  # noqa: E501
        :rtype: int
        """
        return self._ef_construction

    @ef_construction.setter
    def ef_construction(self, ef_construction):
        """Sets the ef_construction of this ImportDatasetRequest.

        controls the size of the candidate queue for edges when adding a node to the graph  # noqa: E501

        :param ef_construction: The ef_construction of this ImportDatasetRequest.  # noqa: E501
        :type: int
        """

        self._ef_construction = ef_construction

    @property
    def m_number_of_edges(self):
        """Gets the m_number_of_edges of this ImportDatasetRequest.  # noqa: E501

        number of neighbors for each node in the HNSW graph  # noqa: E501

        :return: The m_number_of_edges of this ImportDatasetRequest.  # noqa: E501
        :rtype: int
        """
        return self._m_number_of_edges

    @m_number_of_edges.setter
    def m_number_of_edges(self, m_number_of_edges):
        """Sets the m_number_of_edges of this ImportDatasetRequest.

        number of neighbors for each node in the HNSW graph  # noqa: E501

        :param m_number_of_edges: The m_number_of_edges of this ImportDatasetRequest.  # noqa: E501
        :type: int
        """

        self._m_number_of_edges = m_number_of_edges

    @property
    def distance_function(self):
        """Gets the distance_function of this ImportDatasetRequest.  # noqa: E501

        controls the type of distance computation  # noqa: E501

        :return: The distance_function of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._distance_function

    @distance_function.setter
    def distance_function(self, distance_function):
        """Sets the distance_function of this ImportDatasetRequest.

        controls the type of distance computation  # noqa: E501

        :param distance_function: The distance_function of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """
        allowed_values = ["cosine"]  # noqa: E501
        if distance_function not in allowed_values:
            raise ValueError(
                "Invalid value for `distance_function` ({0}), must be one of {1}"  # noqa: E501
                .format(distance_function, allowed_values)
            )

        self._distance_function = distance_function

    @property
    def hnsw_use_ssd(self):
        """Gets the hnsw_use_ssd of this ImportDatasetRequest.  # noqa: E501

        Only for HNSW - controls whether to use SSD or not  # noqa: E501

        :return: The hnsw_use_ssd of this ImportDatasetRequest.  # noqa: E501
        :rtype: bool
        """
        return self._hnsw_use_ssd

    @hnsw_use_ssd.setter
    def hnsw_use_ssd(self, hnsw_use_ssd):
        """Sets the hnsw_use_ssd of this ImportDatasetRequest.

        Only for HNSW - controls whether to use SSD or not  # noqa: E501

        :param hnsw_use_ssd: The hnsw_use_ssd of this ImportDatasetRequest.  # noqa: E501
        :type: bool
        """

        self._hnsw_use_ssd = hnsw_use_ssd

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value
        if issubclass(ImportDatasetRequest, dict):
            for key, value in self.items():
                result[key] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, ImportDatasetRequest):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
